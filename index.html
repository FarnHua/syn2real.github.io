<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="description"
      content="Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition"
    />
    <meta name="keywords" content="Task Vector, ASR, Domain Adaptation" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>
      Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech
      Recognition
    </title>

    <!-- Google Analytics -->
    <script async src=""></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "");
    </script>

    <!-- Fonts and Stylesheets -->
    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="./static/css/bulma.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="./static/css/index.css" />
    <link rel="icon" href="./static/images/favicon.svg" />

    <!-- Scripts -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
  </head>
  <body>
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                Task Arithmetic can Mitigate <nobr>Synthetic-to-Real</nobr> Gap
                in Automatic Speech Recognition
              </h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block"
                  ><a href="https://github.com/jacksukk">Hsuan Su</a
                  ><sup>1</sup>,</span
                >
                <span class="author-block"
                  ><a href="https://github.com/FarnHua">Hua Farn</a
                  ><sup>1</sup>,</span
                >
                <span class="author-block"
                  ><a href="https://sunfanyun.com">Fan-Yun Sun</a
                  ><sup>2</sup>,</span
                >
                <span class="author-block"
                  ><a href="https://www.csie.ntu.edu.tw/~stchen/"
                    >Shang-Tse Chen</a
                  ><sup>1</sup>,</span
                >
                <span class="author-block"
                  ><a href="https://speech.ee.ntu.edu.tw/~hylee/index.php"
                    >Hung-yi Lee</a
                  ><sup>1</sup>,</span
                >
              </div>
              <div class="is-size-5 publication-authors">
                <span class="author-block"
                  ><sup>1</sup>National Taiwan University</span
                >
                <span class="author-block"
                  ><sup>2</sup>Stanford University</span
                >
              </div>
              <div class="publication-links">
                <span class="link-block">
                  <a
                    href="https://arxiv.org/abs/2406.02925"
                    class="external-link button is-normal is-rounded is-dark"
                  >
                    <span class="icon"><i class="ai ai-arxiv"></i></span>
                    <span>arXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a
                    href="https://github.com/jacksukk/SYN2REAL?tab=readme-ov-file&fbclid=IwY2xjawF3ZO9leHRuA2FlbQIxMAABHYIUF-oUyhQi9dKDbqSC9Jm8o-aAKZJMCaYDYOOutGaA-G87ZPmWuWMtrw_aem_V-fD6kxyO1Lg_3L0XXw0TQ"
                    class="external-link button is-normal is-rounded is-dark"
                  >
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Synthetic data is widely used in speech recognition due to the
                availability of text-to-speech models, which facilitate adapting
                models to previously unseen text domains. However, existing
                methods suffer in performance when they fine-tune an automatic
                speech recognition (ASR) model on synthetic data as they suffer
                from the distributional shift commonly referred to as the
                synthetic-to-real gap.
              </p>
              <p>
                In this paper, we find that task vector arithmetic is effective
                at mitigating this gap. Our proposed method, SYN2REAL task
                vector, shows an average improvement of 10.03% in word error
                rate over baselines on the SLURP dataset.
              </p>
              <p>
                Additionally, we show that an average of SYN2REAL task vectors,
                when we have real speeches from multiple different domains, can
                further adapt the original ASR model to perform better on the
                target text domain.
              </p>
              <img
                src="./static/images/syn2real.gif"
                alt="SYN2REAL Task Vector"
                width="100%"
              />
              <p>
                <strong>Overview of the SYN2REAL Task Vector.</strong> The
                pre-trained model is fine-tuned on source domain synthetic and
                real speech data, separately. The difference between their
                parameters forms the SYN2REAL task vector. The SYN2REAL task
                vector is then added to a model fine-tuned on target synthetic
                data to overcome the synthetic-to-real gap.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <!-- What is SYN2REAL Task Vector? Section -->
            <!-- <h2 class="title is-3">What is SYN2REAL Task Vector?</h2> -->
            <!-- <div class="box">
              <div class="content has-text-justified">
                <img
                  src="./static/images/syn2real.gif"
                  alt="SYN2REAL Task Vector"
                  width="100%"
                />
                <p>
                  <strong>Overview of the SYN2REAL Task Vector.</strong> The
                  pre-trained model is fine-tuned on source domain synthetic and
                  real speech data, separately. The difference between their
                  parameters forms the SYN2REAL task vector. The SYN2REAL task
                  vector is then added to a model fine-tuned on target synthetic
                  data to overcome the synthetic-to-real gap.
                </p>
              </div>
            </div> -->

            <!-- Divider between sections -->
            <!-- <hr class="my-6" /> -->
            <!-- How to get SYN2REAL Task Vector? Section -->
            <h2
              class="title is-3"
              style="
                background-color: #f3f3f3;
                width: 100%;
                display: block;
                height: 60px;
                line-height: 60px;
              "
            >
              Domain Mismatch in ASR Domain Adaptation
            </h2>
            <!-- <div class="box"> -->
            <div class="content has-text-justified">
              <div style="text-align: center">
                <figure id="figure-2" style="margin: 20px 0; text-align: center;"></figure>
                <img
                  src="./static/images/domain_shift.png"
                  alt="Main Results"
                  width="70%"
                  style="display: block; margin-left: auto; margin-right: auto"
                />
                <figcaption style="margin-top: 10px; font-style: italic">
                  Figure 2: Domain Shifts in ASR Domain Adaptation
                </figcaption>
                </figure>
              </div>
              <!-- create a transparent line -->
              <p>
                <br />
              </p>

              <p>
                In the context of automatic speech recognition (ASR) domain
                adaptation, domain mismatch can be broadly classified into three
                categories:
              </p>
              <ol>
                <li>
                  <strong>Acoustic Variation Mismatch</strong>: This mismatch
                  refers to differences in speech caused by variations in
                  acoustic properties.
                </li>
                <li>
                  <strong>Textual Topic Mismatch</strong>: This mismatch
                  involves discrepancies in the subject matter or style of the
                  textual content.
                </li>
                <li>
                  <strong>Synthetic vs. Real Speech Mismatch</strong>: This
                  mismatch refers to the acoustic differences between
                  synthesized speech generated from text and actual spoken
                  speech.
                </li>
              </ol>
              <p>
                In this work, we aim to adapt ASR models from source textual
                domains with real speech and text data to a new textual domain
                with only text data. We leverage data synthesized from
                off-the-shelf text-to-speech (TTS) systems to address this
                textual topic mismatch. <a href="#figure-2">Figure 2</a> illustrates the domain shifts
                we focused on in ASR adaptation, depicting the challenges of
                bridging both the textual gap (source vs. target domain) and the
                acoustic gap (synthetic vs. real speech). While previous works
                have shown that adapting ASR models using synthetic data
                effectively addresses textual topic mismatch, ASR models trained
                on synthetic data often underperform compared to those trained
                on real data due to mismatches between synthetic and real
                speech. To overcome this limitation, we propose the SYN2REAL
                task vector, a novel approach designed to bridge the acoustic
                gap between synthetic and real speech data, enhancing the
                performance of ASR models in domain adaptation.
              </p>
            </div>
            <h2
              class="title is-3"
              style="
                background-color: #f3f3f3;
                width: 100%;
                display: block;
                height: 60px;
                line-height: 60px;
              "
            >
              SYN2REAL Task Vector
            </h2>
            <!-- <div class="box"> -->
            <div class="content has-text-justified">
              <div style="text-align: center">
                <figure id="figure-3" style="margin: 20px 0; text-align: center;">
                  <img
                    src="./static/images/method.png"
                    alt="Framework for SYN2REAL task vector in Domain Adaptation for ASR"
                    style="width: 70%; max-width: 100%; display: block; margin: 0 auto;"
                  />
                  <figcaption style="margin-top: 10px; font-style: italic;">
                    Figure 3: Framework for SYN2REAL task vector in Domain Adaptation for ASR.
                  </figcaption>
                </figure>
              </div>
                
                <p style="margin-top: 20px;">
                  The framework in <a href="#figure-3">Figure 3</a> illustrates the process of creating
                  the SYN2REAL task vector by subtracting the parameter differences between a model 
                  fine-tuned on synthetic speech (Source Synthetic) and a model fine-tuned on real 
                  speech (Source Real) from pretrained ASR (PASR). This task vector is then applied 
                  to the target synthetic domain (Target Synthetic) to improve ASR performance by 
                  bridging the gap between synthetic and real speech data.
                </p>
            </div>
            <h2
              class="title is-3"
              style="
                background-color: #f3f3f3;
                width: 100%;
                display: block;
                height: 60px;
                line-height: 60px;
              "
            >
              Main Results
            </h2>
            <!-- <div class="box"> -->
            <div class="content has-text-justified">
              <div style="text-align: center">
                <img
                  src="./static/images/main_results.png"
                  alt="Main Results"
                  width="100%"
                  style="display: block; margin-left: auto; margin-right: auto"
                />
              </div>
              <figcaption style="margin-top: 10px; text-align: left">
                <strong
                  >Table 1: Word Error Rate (WER) Performance Across Various
                  Target Domains.</strong
                >
                Comparison of the baseline Whisper model and the model enhanced
                with the SYN2REAL task vector generated by BARK. The SYN2REAL
                task vector shows an average WER reduction of 10.03% across
                various target domains. Target Synthetic ASR refers to the
                baseline that is finetuned on 17 domains (excluding the target
                domain) real+synthetic data followed by synthetic data from the
                target domains in the SLURP dataset.
              </figcaption>
            </div>
            <!-- </div> -->
          </div>
        </div>
      </div>
    </section>

    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@misc{su2024taskarithmeticmitigatesynthetictoreal,
  title={Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition}, 
  author={Hsuan Su and Hua Farn and Fan-Yun Sun and Shang-Tse Chen and Hung-yi Lee},
  year={2024},
  eprint={2406.02925},
  archivePrefix={arXiv},
  primaryClass={eess.AS},
  url={https://arxiv.org/abs/2406.02925}, 
}</code></pre>
      </div>
    </section>

    <footer class="footer">
      <div class="container">
        <div class="content has-text-centered">
          <a class="icon-link" href="https://github.com/sunfanyunn">
            <i class="fab fa-github"></i>
          </a>
        </div>
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This website is licensed under a
                <a
                  rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/"
                  >Creative Commons Attribution-ShareAlike 4.0 International
                  License</a
                >.
              </p>
              <p>
                The style of this website is borrowed from
                <a href="https://www.zjukg.org/project/SafeEdit/">this website</a>. You are
                free to borrow the source code, we just ask that you link back
                to this page in the footer.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>
  </body>
</html>
